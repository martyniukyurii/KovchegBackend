import asyncio
import re
import json
import requests
from datetime import datetime
from playwright.async_api import async_playwright
from openai import OpenAI
import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Optional

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
load_dotenv()

# –î–æ–¥–∞—î–º–æ –∫–æ—Ä–µ–Ω–µ–≤—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –¥–æ Python path
sys.path.append(str(Path(__file__).parent.parent.parent))
from tools.logger import Logger
from tools.database import SyncDatabase

class M2BomberParser:
    def __init__(self):
        self.browser = None
        self.context = None
        self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.exchange_rates = {}
        self.logger = Logger()
        self.db = SyncDatabase()
        
        # –Ü–º–ø–æ—Ä—Ç—É—î–º–æ TelegramBot –¥–∏–Ω–∞–º—ñ—á–Ω–æ
        from bot.telegram_bot import TelegramBot
        self.telegram_bot = TelegramBot()
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É –¥–ª—è —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        self.results_dir = Path(__file__).parent.parent.parent / "parsed_results" / "individual"
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
    async def init_browser(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –±—Ä–∞—É–∑–µ—Ä–∞ Playwright"""
        playwright = await async_playwright().start()
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ Firefox –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
        self.browser = await playwright.firefox.launch(
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-gpu',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
        )
        
        self.context = await self.browser.new_context(
            user_agent='Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/119.0',
            viewport={'width': 1920, 'height': 1080},
            ignore_https_errors=True
        )
        
    async def close_browser(self):
        """–ó–∞–∫—Ä–∏—Ç—Ç—è –±—Ä–∞—É–∑–µ—Ä–∞ —Ç–∞ Telegram –±–æ—Ç–∞"""
        if self.browser:
            await self.browser.close()
        await self.telegram_bot.close()
            
    async def get_exchange_rates(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è –∫—É—Ä—Å—ñ–≤ –≤–∞–ª—é—Ç –∑ –ù–ë–£"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(
                'https://bank.gov.ua/NBUStatService/v1/statdirectory/exchange?json',
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                rates_data = response.json()
                
                for rate in rates_data:
                    if rate['cc'] == 'USD':
                        self.exchange_rates['USD'] = rate['rate']
                    elif rate['cc'] == 'EUR':
                        self.exchange_rates['EUR'] = rate['rate']
                        
                self.logger.info(f"‚úÖ –û—Ç—Ä–∏–º–∞–Ω–æ –∫—É—Ä—Å–∏ –ù–ë–£: USD={self.exchange_rates.get('USD')}, EUR={self.exchange_rates.get('EUR')}")
                return True
            else:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∫—É—Ä—Å—ñ–≤ –ù–ë–£: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –∫—É—Ä—Å—ñ–≤ –ù–ë–£: {e}")
            self.exchange_rates = {'USD': 41.78, 'EUR': 48.99}
            return False
            
    def convert_currency(self, amount, from_currency):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤–∞–ª—é—Ç"""
        if not self.exchange_rates:
            self.exchange_rates = {'USD': 41.78, 'EUR': 48.99}
            
        if from_currency == 'UAH':
            return {
                'UAH': int(amount),
                'USD': int(amount / self.exchange_rates['USD']),
                'EUR': int(amount / self.exchange_rates['EUR'])
            }
        elif from_currency == 'USD':
            return {
                'UAH': int(amount * self.exchange_rates['USD']),
                'USD': int(amount),
                'EUR': int(amount * self.exchange_rates['USD'] / self.exchange_rates['EUR'])
            }
        elif from_currency == 'EUR':
            return {
                'UAH': int(amount * self.exchange_rates['EUR']),
                'USD': int(amount * self.exchange_rates['EUR'] / self.exchange_rates['USD']),
                'EUR': int(amount)
            }
        else:
            return {'UAH': int(amount), 'USD': int(amount), 'EUR': int(amount)}

    def check_listing_exists(self, url: str) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —ñ—Å–Ω—É—î –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è –≤ –±–∞–∑—ñ"""
        try:
            existing = self.db.parsed_listings.find_one({"url": url})
            return existing is not None
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è: {e}")
            return False
    
    async def save_to_database(self, listing_data: Dict) -> Optional[str]:
        """–ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è –≤ MongoDB —Ç–∞ –≤—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –≤ Telegram"""
        try:
            # –î–æ–¥–∞—î–º–æ –º–µ—Ç–∞-–¥–∞–Ω—ñ
            listing_data['parsed_at'] = datetime.now().isoformat()
            listing_data['source'] = 'M2BOMBER'
            listing_data['is_active'] = True
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –±–∞–∑—É
            result_id = self.db.parsed_listings.create(listing_data)
            
            if result_id:
                self.logger.info(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤ MongoDB: {listing_data.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏')}")
                
                # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –≤ Telegram –æ–¥—Ä–∞–∑—É –ø—ñ—Å–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
                try:
                    await self.telegram_bot.send_to_channel(listing_data)
                    self.logger.info(f"üì§ –í—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram: {listing_data.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏')}")
                except Exception as telegram_error:
                    self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {telegram_error}")
                
                return result_id
            else:
                self.logger.error("–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –±–∞–∑—É")
                return None
                
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ MongoDB: {e}")
            return None

    def extract_listing_urls(self, html_content):
        """–í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è –∑ —Ä–µ–≥–µ–∫—Å—É"""
        pattern = r'href=[\'"]([^\'"]*\/obj\/\d+\/view\/[^\'"]*)[\'"]'
        matches = re.findall(pattern, html_content)
        
        unique_urls = list(set(matches))
        
        full_urls = []
        for url in unique_urls:
            if url.startswith('/'):
                full_urls.append(f'https://ua.m2bomber.com{url}')
            else:
                full_urls.append(url)
                
        return full_urls

    async def extract_phone(self, page):
        """–í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω—É –∑ M2Bomber"""
        try:
            # –°–ø–æ—á–∞—Ç–∫—É —à—É–∫–∞—î–º–æ –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏–π —Ç–µ–ª–µ—Ñ–æ–Ω
            phone_selectors = [
                '.fullcard-author-phone',
                'a[data-id][rel="nofollow"]'
            ]
            
            for selector in phone_selectors:
                try:
                    phone_element = await page.query_selector(selector)
                    if phone_element:
                        phone_text = await phone_element.text_content()
                        
                        # –Ø–∫—â–æ —Ç–µ–ª–µ—Ñ–æ–Ω –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏–π (xxx-xx-xx), –Ω–∞–º–∞–≥–∞—î–º–æ—Å—è –π–æ–≥–æ —Ä–æ–∑–∫—Ä–∏—Ç–∏
                        if 'xxx' in phone_text:
                            # –ù–∞—Ç–∏—Å–∫–∞—î–º–æ –Ω–∞ –µ–ª–µ–º–µ–Ω—Ç –¥–ª—è —Ä–æ–∑–∫—Ä–∏—Ç—Ç—è –Ω–æ–º–µ—Ä—É
                            await phone_element.click()
                            await page.wait_for_timeout(3000)
                            
                            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –∑–º—ñ–Ω–∏–≤—Å—è —Ç–µ–∫—Å—Ç
                            updated_text = await phone_element.text_content()
                            if updated_text and updated_text != phone_text and 'xxx' not in updated_text:
                                phone_text = updated_text
                        
                        # –í–∏—Ç—è–≥—É—î–º–æ –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω—É
                        # –§–æ—Ä–º–∞—Ç: (066) xxx-xx-xx –∞–±–æ +380661234567
                        phone_match = re.search(r'\((\d{3})\)\s*(\d{3})-(\d{2})-(\d{2})', phone_text)
                        if phone_match:
                            return f"+380{phone_match.group(1)}{phone_match.group(2)}{phone_match.group(3)}{phone_match.group(4)}"
                        
                        # –§–æ—Ä–º–∞—Ç: 0661234567 –∞–±–æ +380661234567
                        phone_match = re.search(r'(\+?3?8?0?)(\d{2})(\d{3})(\d{2})(\d{2})', phone_text.replace('-', '').replace(' ', ''))
                        if phone_match and len(phone_match.group(0).replace('+', '').replace('380', '0')) == 10:
                            phone_digits = phone_match.group(2) + phone_match.group(3) + phone_match.group(4) + phone_match.group(5)
                            return f"+380{phone_digits}"
                            
                except Exception as e:
                    continue
            
            # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –≤ –æ—Å–Ω–æ–≤–Ω–∏—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–∞—Ö, —à—É–∫–∞—î–º–æ –≤ —Ñ–æ—Ä–º–∞—Ö
            try:
                form_elements = await page.query_selector_all('form[action*="/phone/"]')
                for form in form_elements:
                    action = await form.get_attribute('action')
                    if action:
                        phone_match = re.search(r'/phone/(\d+)/', action)
                        if phone_match:
                            phone_digits = phone_match.group(1)
                            if len(phone_digits) == 10:
                                return f"+380{phone_digits}"
            except:
                pass
                    
            return None
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–µ–ª–µ—Ñ–æ–Ω—É: {e}")
            return None

    async def get_location_from_openai(self, description, address_text=""):
        """–í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ª–æ–∫–∞—Ü—ñ—ó —á–µ—Ä–µ–∑ OpenAI API"""
        try:
            text_to_analyze = f"{address_text} {description}".lower()
            
            street_patterns = [
                r'–≤—É–ª\.?\s+([–∞-—è—ë—ñ—ó\s\.\-]+?)[\s,\d]',
                r'–≤—É–ª–∏—Ü—è\s+([–∞-—è—ë—ñ—ó\s\.\-]+?)[\s,\d]',
                r'–ø—Ä–æ—Å–ø\.?\s+([–∞-—è—ë—ñ—ó\s\.\-]+?)[\s,\d]',
                r'–ø—Ä–æ—Å–ø–µ–∫—Ç\s+([–∞-—è—ë—ñ—ó\s\.\-]+?)[\s,\d]',
                r'–±—É–ª\.?\s+([–∞-—è—ë—ñ—ó\s\.\-]+?)[\s,\d]',
                r'–±—É–ª—å–≤–∞—Ä\s+([–∞-—è—ë—ñ—ó\s\.\-]+?)[\s,\–¥]'
            ]
            
            for pattern in street_patterns:
                match = re.search(pattern, text_to_analyze)
                if match:
                    street = match.group(1).strip()
                    if len(street) > 3:
                        return f"–í—É–ª–∏—Ü—è {street.title()}, –ß–µ—Ä–Ω—ñ–≤—Ü—ñ"
            
            prompt = f"""
            –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü–µ–π —Ç–µ–∫—Å—Ç —ñ –≤–∏–∑–Ω–∞—á –∞–¥—Ä–µ—Å—É –Ω–µ—Ä—É—Ö–æ–º–æ—Å—Ç—ñ –≤ –ß–µ—Ä–Ω—ñ–≤—Ü—è—Ö.
            
            –ê–¥—Ä–µ—Å–∞: {address_text}
            –û–ø–∏—Å: {description[:500]}
            
            –ü–æ–≤–µ—Ä–Ω–∏ –¢–Ü–õ–¨–ö–ò –∞–¥—Ä–µ—Å—É –≤ —Ñ–æ—Ä–º–∞—Ç—ñ: "–í—É–ª–∏—Ü—è –ù–∞–∑–≤–∞, –ß–µ—Ä–Ω—ñ–≤—Ü—ñ" –∞–±–æ "–†–∞–π–æ–Ω, –ß–µ—Ä–Ω—ñ–≤—Ü—ñ".
            –Ø–∫—â–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –≤—É–ª–∏—Ü—ñ –Ω–µ–º–∞—î, –≤–∫–∞–∂–∏ —Ä–∞–π–æ–Ω (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: "–¶–µ–Ω—Ç—Ä, –ß–µ—Ä–Ω—ñ–≤—Ü—ñ").
            """
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50,
                temperature=0.1
            )
            
            location = response.choices[0].message.content.strip()
            
            if "—á–µ—Ä–Ω—ñ–≤—Ü—ñ" not in location.lower():
                location += ", –ß–µ—Ä–Ω—ñ–≤—Ü—ñ"
                
            return location
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ª–æ–∫–∞—Ü—ñ—ó: {e}")
            return "–ß–µ—Ä–Ω—ñ–≤—Ü—ñ"

    async def extract_images(self, page):
        """–í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è"""
        try:
            images = []
            
            image_selectors = [
                '.fullcard-big-slider img',
                '.fullcard-little-slider img',
                'img[data-lazy]',
                '.item-long-image-wrapper img',
                'a[data-fancybox="gallery"] img'
            ]
            
            await page.wait_for_timeout(2000)
            
            for selector in image_selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    for element in elements:
                        src = await element.get_attribute('data-lazy')
                        if not src:
                            src = await element.get_attribute('src')
                        if not src:
                            src = await element.get_attribute('data-src')
                            
                        if src and src.startswith('/storage/'):
                            full_url = f'https://ua.m2bomber.com{src}'
                            if full_url not in images:
                                images.append(full_url)
                        elif src and src.startswith('http'):
                            if src not in images:
                                images.append(src)
                                
                except Exception as e:
                    continue
            
            return images[:10]
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å: {e}")
            return []

    async def extract_listing_data(self, page, url):
        """–í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –æ–∫—Ä–µ–º–æ–≥–æ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è"""
        try:
            data = {'url': url}
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_selectors = ['h1', '.card-title h1', '.fullcard-title h1']
            for selector in title_selectors:
                try:
                    title_element = await page.query_selector(selector)
                    if title_element:
                        title = await title_element.text_content()
                        if title and len(title.strip()) > 5:
                            data['title'] = title.strip()
                            break
                except:
                    continue
            
            # –¶—ñ–Ω–∞
            try:
                price_element = await page.query_selector('.price-full, #fullPriceValueHolder, #priceValueHolder')
                if price_element:
                    price_text = await price_element.text_content()
                    
                    price_match = re.search(r'([\d\s]+)\s*([‚Ç¥$‚Ç¨])', price_text.replace(' ', ''))
                    if price_match:
                        price_value = int(price_match.group(1).replace(' ', ''))
                        currency_symbol = price_match.group(2)
                        
                        currency_map = {'‚Ç¥': 'UAH', '$': 'USD', '‚Ç¨': 'EUR'}
                        currency = currency_map.get(currency_symbol, 'UAH')
                        
                        data['price'] = price_value
                        data['currency'] = currency
                        
                        converted = self.convert_currency(price_value, currency)
                        data['price_uah'] = converted['UAH']
                        data['price_usd'] = converted['USD']
                        data['price_eur'] = converted['EUR']
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ü—ñ–Ω–∏: {e}")
            
            # –¢–µ–≥–∏, –ø–ª–æ—â–∞ —Ç–∞ –∫—ñ–º–Ω–∞—Ç–∏
            try:
                tags_elements = await page.query_selector_all('.fullcard-tags li')
                tags = []
                
                for element in tags_elements:
                    text = await element.text_content()
                    if text and text.strip():
                        clean_text = text.strip()
                        tags.append(clean_text)
                        
                        # –í–∏—Ç—è–≥—É—î–º–æ –ø–ª–æ—â—É –∑ —Ç–µ–≥—ñ–≤
                        area_match = re.search(r'(\d+)\s*–º¬≤', clean_text)
                        if area_match and 'area' not in data:
                            data['area'] = float(area_match.group(1))
                        
                        # –í–∏—Ç—è–≥—É—î–º–æ –ø–æ–≤–µ—Ä—Ö –∑ —Ç–µ–≥—ñ–≤  
                        floor_match = re.search(r'–ø–æ–≤–µ—Ä—Ö\s*(\d+)', clean_text)
                        if floor_match and 'floor' not in data:
                            data['floor'] = int(floor_match.group(1))
                            
                        # –í–∏—Ç—è–≥—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫—ñ–º–Ω–∞—Ç
                        rooms_match = re.search(r'(\d+)-–∫—ñ–º–Ω', clean_text)
                        if rooms_match and 'rooms' not in data:
                            data['rooms'] = int(rooms_match.group(1))
                
                if tags:
                    data['tags'] = tags
                    self.logger.info(f"üè∑Ô∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(tags)} —Ç–µ–≥—ñ–≤: {', '.join(tags)}")
                        
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ç–µ–≥—ñ–≤/–ø–ª–æ—â—ñ/–ø–æ–≤–µ—Ä—Ö—É: {e}")
            
            # –û–ø–∏—Å
            try:
                desc_selectors = ['.fullcard-desc', '.item-card-long-desc', '.fullcard-description']
                for selector in desc_selectors:
                    desc_element = await page.query_selector(selector)
                    if desc_element:
                        description = await desc_element.text_content()
                        if description and len(description.strip()) > 10:
                            data['description'] = description.strip()
                            break
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –æ–ø–∏—Å—É: {e}")
            
            # –ê–¥—Ä–µ—Å–∞
            try:
                address_selectors = ['.fullcard-address', '.item-card-long-address', 'address']
                for selector in address_selectors:
                    address_element = await page.query_selector(selector)
                    if address_element:
                        address = await address_element.text_content()
                        if address and len(address.strip()) > 5:
                            data['address'] = address.strip()
                            break
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∞–¥—Ä–µ—Å–∏: {e}")
            
            # –¢–µ–ª–µ—Ñ–æ–Ω
            phone = await self.extract_phone(page)
            if phone:
                data['phone'] = phone
            
            # –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            images = await self.extract_images(page)
            if images:
                data['images'] = images
                self.logger.info(f"üñºÔ∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(images)} –∑–æ–±—Ä–∞–∂–µ–Ω—å")
            
            # –õ–æ–∫–∞—Ü—ñ—è —á–µ—Ä–µ–∑ OpenAI
            if data.get('description') or data.get('address'):
                location = await self.get_location_from_openai(
                    data.get('description', ''),
                    data.get('address', '')
                )
                data['location'] = location
            
            data['parsed_at'] = datetime.now().isoformat()
            
            return data
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
            return {'url': url, 'error': str(e)}

    async def parse_listing_page(self, url, property_type):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∑—ñ —Å–ø–∏—Å–∫–æ–º –æ–≥–æ–ª–æ—à–µ–Ω—å"""
        try:
            page = await self.context.new_page()
            
            self.logger.info(f"üîç –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Å—Ç–æ—Ä—ñ–Ω–∫—É: {url}")
            await page.goto(url, wait_until='domcontentloaded', timeout=30000)
            await page.wait_for_timeout(3000)
            
            html_content = await page.content()
            listing_urls = self.extract_listing_urls(html_content)
            
            self.logger.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(listing_urls)} –æ–≥–æ–ª–æ—à–µ–Ω—å")
            
            parsed_listings = []
            
            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—î–º–æ –±—Ä–∞—É–∑–µ—Ä –∫–æ–∂–Ω—ñ 10 –æ–≥–æ–ª–æ—à–µ–Ω—å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º'—è—Ç—ñ
            browser_restart_interval = 10
            
            for i, listing_url in enumerate(listing_urls[:20], 1):
                # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—î–º–æ –±—Ä–∞—É–∑–µ—Ä –ø–µ—Ä—ñ–æ–¥–∏—á–Ω–æ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º'—è—Ç—ñ
                if i > 1 and (i - 1) % browser_restart_interval == 0:
                    self.logger.info(f"üîÑ –ü—Ä–æ—Ñ—ñ–ª–∞–∫—Ç–∏—á–Ω–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ –ø—ñ—Å–ª—è {i-1} –æ–≥–æ–ª–æ—à–µ–Ω—å...")
                    try:
                        await self.close_browser()
                        await asyncio.sleep(3)
                        await self.init_browser()
                        self.logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω–æ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º'—è—Ç—ñ")
                    except Exception as e:
                        self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ—Ñ—ñ–ª–∞–∫—Ç–∏—á–Ω–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫—É: {e}")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è –≤–∂–µ —ñ—Å–Ω—É—î –≤ –±–∞–∑—ñ –°–ü–û–ß–ê–¢–ö–£
                if self.check_listing_exists(listing_url):
                    self.logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ (–≤–∂–µ —ñ—Å–Ω—É—î): {listing_url}")
                    continue
                
                self.logger.info(f"üìÑ –ü–∞—Ä—Å–∏–º–æ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è {i}/{len(listing_urls[:20])}: {listing_url}")
                
                # –î–æ–¥–∞—î–º–æ –æ–±—Ä–æ–±–∫—É –ø–æ–º–∏–ª–æ–∫ –±—Ä–∞—É–∑–µ—Ä–∞ –∑ –ø–æ–≤—Ç–æ—Ä–Ω–∏–º–∏ —Å–ø—Ä–æ–±–∞–º–∏
                max_retries = 3
                listing_page = None
                
                for attempt in range(max_retries):
                    try:
                        listing_page = await self.context.new_page()
                        await listing_page.goto(listing_url, wait_until='domcontentloaded', timeout=30000)
                        await listing_page.wait_for_timeout(2000)
                        
                        listing_data = await self.extract_listing_data(listing_page, listing_url)
                        listing_data['property_type'] = property_type
                        
                        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –±–∞–∑—É —Ç–∞ –≤—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –≤ Telegram
                        await self.save_to_database(listing_data)
                        
                        parsed_listings.append(listing_data)
                        
                        await listing_page.close()
                        listing_page = None
                        break  # –£—Å–ø—ñ—à–Ω–æ - –≤–∏—Ö–æ–¥–∏–º–æ –∑ —Ü–∏–∫–ª—É –ø–æ–≤—Ç–æ—Ä—ñ–≤
                        
                    except Exception as e:
                        error_msg = str(e)
                        self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É {listing_url} (—Å–ø—Ä–æ–±–∞ {attempt + 1}/{max_retries}): {error_msg}")
                        
                        # –ó–∞–∫—Ä–∏–≤–∞—î–º–æ —Å—Ç–æ—Ä—ñ–Ω–∫—É —è–∫—â–æ –≤–æ–Ω–∞ –≤—ñ–¥–∫—Ä–∏—Ç–∞
                        if listing_page:
                            try:
                                await listing_page.close()
                            except:
                                pass
                            listing_page = None
                        
                        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ –ø–æ–º–∏–ª–∫–∞ –ø–∞–º'—è—Ç—ñ –∞–±–æ –±—Ä–∞—É–∑–µ—Ä–∞
                        memory_errors = ["collected to prevent unbounded heap growth", "object has been collected"]
                        browser_errors = ["playwright", "connection", "_object"]
                        
                        is_memory_error = any(err in error_msg.lower() for err in memory_errors)
                        is_browser_error = any(err in error_msg.lower() for err in browser_errors)
                        
                        if is_memory_error or is_browser_error:
                            self.logger.warning("üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—î–º–æ –±—Ä–∞—É–∑–µ—Ä —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É –ø–∞–º'—è—Ç—ñ/–±—Ä–∞—É–∑–µ—Ä–∞...")
                            try:
                                await self.close_browser()
                                await asyncio.sleep(3)
                                await self.init_browser()
                                self.logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω–æ")
                            except Exception as browser_error:
                                self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫—É –±—Ä–∞—É–∑–µ—Ä–∞: {browser_error}")
                        
                        if attempt == max_retries - 1:
                            self.logger.error(f"üí• –ù–µ –≤–¥–∞–ª–æ—Å—è —Å–ø–∞—Ä—Å–∏—Ç–∏ {listing_url} –ø—ñ—Å–ª—è {max_retries} —Å–ø—Ä–æ–±")
                        else:
                            await asyncio.sleep(3)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                
                await asyncio.sleep(1)
            
            await page.close()
            return parsed_listings
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏ {url}: {e}")
            return []

    async def parse_all_m2bomber_urls(self, urls_data):
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Å—ñ—Ö M2Bomber URL"""
        try:
            await self.get_exchange_rates()
            await self.init_browser()
            
            all_parsed_data = []
            
            m2bomber_urls = [item for item in urls_data if item.get('site') == 'M2BOMBER']
            
            self.logger.info(f"üéØ –ó–Ω–∞–π–¥–µ–Ω–æ {len(m2bomber_urls)} M2Bomber URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É")
            
            for url_item in m2bomber_urls:
                url = url_item['url']
                property_type = url_item.get('type', 'unknown')
                
                self.logger.info(f"\nüöÄ –ü–∞—Ä—Å–∏–º–æ M2Bomber: {property_type} - {url}")
                
                listings = await self.parse_listing_page(url, property_type)
                
                self.logger.info(f"‚úÖ –û—Ç—Ä–∏–º–∞–Ω–æ {len(listings)} –æ–≥–æ–ª–æ—à–µ–Ω—å –∑ {url}")
                all_parsed_data.extend(listings)
                
                await asyncio.sleep(2)
            
            await self.close_browser()
            
            self.logger.info(f"\nüéâ –í—Å—å–æ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ M2Bomber –æ–≥–æ–ª–æ—à–µ–Ω—å: {len(all_parsed_data)}")
            return all_parsed_data
            
        except Exception as e:
            self.logger.error(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ M2Bomber –ø–∞—Ä—Å–µ—Ä–∞: {e}")
            if self.browser:
                await self.close_browser()
            return [] 